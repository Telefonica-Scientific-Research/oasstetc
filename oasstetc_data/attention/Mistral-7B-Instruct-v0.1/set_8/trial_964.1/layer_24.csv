text;attention
A;0.9999722684146997
good;3.110849561942554e-07
machine;2.598259947916787e-07
learning;2.737726306101706e-07
model;2.6926838690929664e-07
for;2.2467205193114582e-07
binary;4.386455879307737e-07
classification;2.992689229833972e-07
on;2.029952060628172e-07
the;1.9574589147436679e-07
Amazon;4.662530052898846e-07
reviews;3.2826370898260963e-07
dataset;2.3460614236506372e-07
is;2.7918627319532324e-07
a;2.1166604196360787e-07
Long;3.0297620593033766e-07
Short-Term;3.558894553087551e-07
Memory;2.7941787599754834e-07
(LSTM);5.419419068699779e-07
network;2.5413653278144834e-07
with;2.346217136379575e-07
a;2.0883634581757906e-07
Convolutional;4.785335536346909e-07
Neural;2.232317574704514e-07
Network;2.317821483220113e-07
(CNN);3.9438767298600326e-07
layer.;4.291039857310486e-07
This;2.0740076504642446e-07
model;2.0107768720781869e-07
can;1.9147178978541205e-07
be;2.678957685686463e-07
fine-tuned;1.5420209506146376e-06
or;2.0739941140648436e-07
trained;2.1837344575957006e-07
from;1.919003842162715e-07
scratch;2.1849257529791524e-07
depending;2.1129399983176797e-07
on;1.922097465685362e-07
your;1.937671273901973e-07
preference.;3.052739007123528e-07
LSTMs.;4.2420545058234825e-07
are;2.0367793519388805e-07
great;2.1393701996770415e-07
for;2.1294522094874954e-07
handling;2.4131357070979187e-07
sequential;2.2533784736593168e-07
data,;2.418221639019528e-07
such;1.9337398025814798e-07
as;1.9501479180915568e-07
text;2.0348497094286577e-07
data,;1.9701822052562468e-07
and;1.8038423513715373e-07
the;1.76932922958567e-07
CNN;2.2671287590948444e-07
layer;1.8462173462592435e-07
can;1.892920103266481e-07
help;1.8236661397253327e-07
extract;1.8960028678914175e-07
relevant;1.7994582769822694e-07
features;1.8429750797224105e-07
from;1.7183282337252924e-07
the;1.7654321579231934e-07
text;1.799053216397334e-07
data.;2.67240230156046e-07
For;2.442696944581604e-07
inference;3.021218280547651e-07
speed,;2.9289562880481593e-07
you;2.032396714369802e-07
can;1.8501964409620995e-07
use;1.8706984284925903e-07
the;1.8355774616360022e-07
TensorRT;3.774270106638292e-07
library;2.1104929966319636e-07
by;2.097641486095191e-07
NVIDIA;2.43859220358575e-07
to;2.1684051451469598e-07
optimize;2.0110218637563615e-07
the;1.8156741242235912e-07
model;1.8499649495218975e-07
for;1.9781655845744447e-07
deployment;1.8536302506498487e-07
on;1.7918514301026531e-07
GPUs.;3.2149880756958024e-07
In;1.918387596189968e-07
terms;1.8453066064338347e-07
of;1.8809512127909329e-07
metrics,;2.6815534756791933e-07
you;1.8787973185401185e-07
can;1.7829640515310243e-07
use;1.9007111591005763e-07
accuracy,;2.330429848330377e-07
precision,;2.2507890036254075e-07
and;1.763348099723731e-07
AUC;2.1313392097039134e-07
to;1.8698620136628076e-07
evaluate;1.7764339830802865e-07
the;1.78837957264359e-07
performance;1.7677931169870675e-07
of;1.7040410980671176e-07
the;1.7377787442073966e-07
model.;2.4495619193362136e-07
During;1.8412025163090002e-07
training,;2.155610476872223e-07
you;1.7792881587690523e-07
can;1.736587106160265e-07
use;1.8230255397578784e-07
binary;2.512409981508028e-07
cross-entropy;3.079028754222005e-07
loss;1.8639355509248136e-07
as;1.7434715693962146e-07
the;1.7586884495085398e-07
loss;1.757802617804426e-07
function;1.7741513802451875e-07
to;1.9045674768913402e-07
optimize.;1.8362337590682356e-07
