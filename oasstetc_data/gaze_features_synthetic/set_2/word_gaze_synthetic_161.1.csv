;fix_number;first_fix_duration;GPT;fix_duration;fixProp;text
0;3.6507082;0.9337139;0.69485056;1.1911669;19.934711;the
1;24.880142;4.2503347;7.2223706;8.735696;89.47444;easiest
2;12.469022;2.8772538;5.2645555;4.0339828;66.85731;way
3;7.2563;1.9363053;2.445133;2.2982318;46.773247;to
4;21.886044;4.114359;5.8751783;7.493796;87.357765;import
5;9.582011;2.1977994;2.8119862;3.1563036;49.521294;the
6;22.787819;4.7579727;8.868938;8.971176;88.729416;bert
7;23.56069;4.512507;9.344036;8.197232;92.115585;language
8;17.88153;4.1493244;7.4769654;5.9079733;89.79196;model
9;9.46568;2.4067943;3.278747;3.3983445;52.754185;into
10;17.58485;3.887636;7.9424314;6.3147407;78.25347;python
11;11.850513;2.6701217;4.3467817;4.0809584;58.221714;for
12;15.441571;3.157941;4.588484;5.0925684;67.04515;use
13;11.767672;2.5942154;4.0111365;3.8335762;57.978676;with
14;24.438519;5.0645485;11.024286;9.481107;93.12791;pytorch
15;4.209138;1.0015615;1.6499918;1.3552566;24.346998;is
16;18.919483;3.807732;5.2692037;6.441164;83.38642;using
17;6.1377387;1.5399351;1.8210101;1.7884707;38.49737;the
18;23.551994;4.7106204;9.286275;8.399796;93.277794;hugging
19;17.250238;4.0324793;8.830312;5.803269;81.991;face
20;28.398571;5.120279;13.499631;10.138774;100.70872;transformer's
21;18.250614;3.8583171;7.9792385;6.2797546;81.27873;library,
22;12.8090315;3.2417495;3.7860148;4.1739364;69.635376;which
23;10.782579;2.5648901;2.9545386;3.529691;59.130634;has
24;15.429133;3.3600655;5.0306387;4.665383;77.48823;built
25;6.9655585;1.849954;1.3526261;1.9959707;45.5969;in
26;16.863226;4.087137;6.071057;5.4950852;88.812195;methods
27;7.4189534;1.818833;1.9398632;2.3355713;42.983597;for
28;27.169722;4.7685347;13.087899;9.73378;93.77789;pre-training,
29;24.86994;4.5166063;13.321284;8.86874;89.73698;inference,
30;4.610273;1.1877391;1.9942658;1.3006061;28.47819;and
31;22.668024;4.2657943;9.39738;7.8403893;85.43637;deploying
32;15.723486;4.345959;17.356085;6.1628304;78.79332;bert.
33;13.307919;3.0502548;6.703232;5.6488686;53.050655;â€˜**
34;15.232065;3.3144445;5.2536855;5.9219055;62.687256;from
35;26.735313;4.2867503;13.28585;9.068;89.64504;transformers
36;19.855694;3.5940652;7.8049235;7.485174;69.137276;import
37;26.443357;4.2921224;12.006643;9.849809;84.13759;autotokenizer,
38;22.421263;4.3683853;10.242122;8.457433;82.393875;bertmodel
39;18.038153;3.6664371;7.0746617;7.031203;69.25464;import
40;14.810842;3.898376;5.458406;5.880906;72.93393;torch
41;33.485825;4.84043;15.477642;12.398942;92.98536;tokenizer
42;8.52936;1.9636283;3.3918397;3.6365564;37.53155;=
43;34.949295;4.9811625;17.948084;13.851731;90.4271;"autotokenizer.from_pretrained(""bert-base-uncased"")"
44;18.86694;3.7302876;7.0131097;6.58985;78.68976;model
45;5.688703;1.6105;2.081825;2.6837592;29.52222;=
46;35.464516;4.7043934;18.532381;14.03218;91.131485;"bertmodel.from_pretrained(""bert-base-uncased"")"
47;22.251165;3.527909;9.537114;7.3728576;81.180595;inputs
48;6.7152596;1.371118;2.8410738;2.8677976;29.707281;=
49;35.72514;4.7393117;15.398113;13.282812;92.14408;"tokenizer(""hello,"
50;8.801808;1.8576918;4.417647;2.784399;45.353283;my
51;18.49371;3.4012618;9.284835;5.919285;78.6273;dog
52;6.4604807;1.8627849;3.082225;2.1339796;39.083508;is
53;18.263334;3.8314836;8.203376;6.2934422;83.620995;"cute"","
54;35.977924;3.9969952;11.822815;12.654071;86.571175;"return_tensors=""pt"")"
55;28.869247;4.0960674;10.183709;9.870846;91.23933;outputs
56;8.250137;1.6388029;3.284782;3.4004047;32.85601;=
57;31.329792;4.1929007;12.414554;11.066183;88.56873;model(**inputs)
58;35.841545;4.456801;12.951168;12.968896;91.87736;last_hidden_states
59;7.5249257;1.6859343;3.0440748;2.8701336;35.033516;=
60;30.099613;4.4120345;16.75014;10.620907;92.958206;outputs.last_hidden_state
61;10.647518;3.3307188;16.850174;4.320026;64.5012;***
