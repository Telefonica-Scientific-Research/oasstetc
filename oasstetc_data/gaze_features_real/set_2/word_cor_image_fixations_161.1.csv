number;fix_duration;first_fix_duration;fix_number;fix_duration_n;first_fix_duration_n;fix_number_n;text
0;0.0;0.0;0.0;0.0;0.0;0.0;The
1;0.8975000000000001;0.27505;3.0;0.021250610956649298;0.020413614339620037;0.0225985401459854;easiest
2;0.7036499999999999;0.30725;2.5;0.01666993359700757;0.02224164945244707;0.0185985401459854;way
3;0.1456;0.1456;0.5;0.003478219323706119;0.011251584185960251;0.0036496350364963502;to
4;0.8975;0.3073;3.0;0.021111107406927176;0.0223654658570245;0.022948905109489052;import
5;0.39615;0.25055;1.5;0.009385563820451505;0.01852180440403997;0.0112992700729927;the
6;0.2917;0.146;1.0;0.006767180681636279;0.010198094493028971;0.008;BERT
7;1.3993;0.25895;5.5;0.033210110213722034;0.018809219801368807;0.040846715328467155;language
8;2.2652;0.3639;6.5;0.05382840290207945;0.02625806902873521;0.048145985401459854;model
9;0.0;0.0;0.0;0.0;0.0;0.0;into
10;2.17555;0.41275;6.5;0.051513946938145865;0.03045383055850171;0.048846715328467155;python
11;0.13745;0.13745;0.5;0.0032835250415069093;0.010621773670056567;0.0036496350364963502;for
12;0.97845;0.5337000000000001;2.0;0.02292782493532887;0.03896048859921443;0.0152992700729927;use
13;1.73095;0.44495;4.5;0.04118303350385755;0.03258193269732384;0.0331970802919708;with
14;1.1725999999999999;0.4206;2.5;0.027381786933410094;0.031301105678157776;0.01964963503649635;PyTorch
15;0.17785;0.17785;0.5;0.004248635348359432;0.01374377917220488;0.0036496350364963502;is
16;0.186;0.186;0.5;0.004443329630558641;0.01437358968810856;0.0036496350364963502;using
17;0.0;0.0;0.0;0.0;0.0;0.0;the
18;1.05125;0.20205;3.5;0.024795229579868277;0.015073919280178795;0.0265985401459854;Hugging
19;0.4529;0.29115;1.0;0.010819268761720477;0.02249930450372477;0.0072992700729927005;Face
20;0.8976;0.29905;3.0;0.02131994085467492;0.02178846092804273;0.02224817518248175;Transformer's
21;0.86555;0.25070000000000003;3.0;0.020582168825863757;0.018352167408768737;0.02224817518248175;library,
22;0.7842;0.275;3.0;0.018555314131777047;0.020110054815510897;0.0225985401459854;which
23;0.7034499999999999;0.5418000000000001;1.5;0.016470023293093165;0.03946648271054068;0.01164963503649635;has
24;0.3397;0.16175;1.0;0.008115048793014895;0.01249961361318043;0.0072992700729927005;built
25;0.2266;0.2266;0.5;0.005413217711207462;0.017511050663039783;0.0036496350364963502;in
26;1.4154499999999999;0.4692;4.5;0.033316977324126126;0.03403588920987518;0.03424817518248175;methods
27;0.12135;0.12135;0.5;0.00281521212107152;0.008476292922801821;0.004;for
28;2.4748;0.3557;8.5;0.05837278570546631;0.02562588012496251;0.0644963503649635;pre-training,
29;0.89005;0.55835;2.0;0.020854847803257488;0.04026301334722815;0.0152992700729927;inference,
30;0.0;0.0;0.0;0.0;0.0;0.0;and
31;1.4722;0.36395;4.0;0.034499472412199576;0.026323208960407657;0.030948905109489052;deploying
32;1.0593;0.27490000000000003;2.5;0.024680799605273532;0.020342974892046194;0.01964963503649635;BERT.
33;0.6471;0.46105;2.0;0.015285392354996546;0.03436681309527013;0.0152992700729927;â€˜**
34;0.12935;0.12935;0.5;0.0030008050091520485;0.009035092621049984;0.004;from
35;0.93835;0.3074;3.0;0.021858174985697382;0.022433355546647646;0.02364963503649635;transformers
36;0.75215;0.34785;2.5;0.017683660080710942;0.02579987272991844;0.019299270072992702;import
37;1.5042;0.3639;5.0;0.03526429558649181;0.02721991754027887;0.03894890510948905;AutoTokenizer,
38;0.8491500000000001;0.2183;2.5;0.01985006479146265;0.016087543150536968;0.019299270072992702;BertModel
39;0.6147;0.12135;2.0;0.014260493537887626;0.008476292922801821;0.016;import
40;0.784;0.0647;2.0;0.018188103031891816;0.004519292559582017;0.016;torch
41;1.02705;0.2993;3.5;0.024211566398845995;0.02168745636255799;0.0265985401459854;tokenizer
42;0.0;0.0;0.0;0.0;0.0;0.0;=
43;4.14825;0.46115;13.0;0.09705542062075641;0.03293288217459112;0.10084671532846716;"AutoTokenizer.from_pretrained(""bert-base-uncased"")"
44;0.12135;0.12135;0.5;0.00281521212107152;0.008476292922801821;0.004;model
45;0.1779;0.1779;0.5;0.0041271218486907575;0.012426308289793523;0.004;=
46;0.7921;0.23445;3.0;0.018543213163348463;0.017157314938552146;0.0232992700729927;"BertModel.from_pretrained(""bert-base-uncased"")"
47;0.10515;0.10515;0.5;0.002511914573404522;0.008125714815616211;0.0036496350364963502;inputs
48;0.0;0.0;0.0;0.0;0.0;0.0;=
49;0.51745;0.22649999999999998;1.5;0.012082460594524799;0.01666179832156804;0.01164963503649635;"tokenizer(""Hello,"
50;0.0;0.0;0.0;0.0;0.0;0.0;my
51;0.21825;0.21825;1.0;0.005096659239561376;0.015604983247059473;0.00764963503649635;dog
52;0.0;0.0;0.0;0.0;0.0;0.0;is
53;0.42835;0.1049;1.5;0.00993733920116181;0.007327261043279036;0.012;"cute"","
54;0.4285;0.16165;1.0;0.00994081906781332;0.01129124640272694;0.008;"return_tensors=""pt"")"
55;0.0;0.0;0.0;0.0;0.0;0.0;outputs
56;0.0;0.0;0.0;0.0;0.0;0.0;=
57;0.84915;0.267;2.5;0.020218326572410183;0.019912598206734543;0.0185985401459854;model(**inputs)
58;0.22655;0.12145;1.0;0.005412023267758388;0.009385335847423574;0.0072992700729927005;last_hidden_states
59;0.0;0.0;0.0;0.0;0.0;0.0;=
60;0.9138999999999999;0.356;3.0;0.0213634157964002;0.026608312255108797;0.02364963503649635;outputs.last_hidden_state
61;0.0;0.0;0.0;0.0;0.0;0.0;***
