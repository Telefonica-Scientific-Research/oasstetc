text;attention
A;3.8983242963009195e-16
suitable;3.4999759326835023e-16
model;3.9039668389687264e-16
for;3.65888779623312e-16
binary;4.036373246831708e-16
classification;4.3066621323740656e-16
on;3.7457814048483505e-16
the;4.1893614548380786e-16
Amazon;3.87630507589005e-16
reviews;4.1377846158664794e-16
dataset;4.099813835362162e-16
could;3.7178459541601167e-16
be;3.60686438029281e-16
a;4.820493386459297e-16
fine-tuned;4.635483407053939e-15
BERT;3.7143259402640456e-16
(Bidirectional;8.059001602436017e-16
Encoder;5.325276497290945e-16
Representations;4.690965979926724e-16
from;4.306158778844265e-16
Transformers);7.30692392380363e-16
model.;0.3611710253179568
Given;3.650574683988011e-16
the;3.619825785446828e-16
large;3.5162614085836854e-16
number;3.5423698583303486e-16
of;3.5347750366373084e-16
training;3.660066063042614e-16
samples;4.337220728404723e-16
(1.8;4.840139966767628e-16
million);5.823368581927635e-16
and;3.9361012600674737e-16
the;3.6625585362567297e-16
longest;3.9096930517006066e-16
sequence;3.9255135035417236e-16
length;4.008294704831309e-16
of;4.33133812579981e-16
258,;2.071953815449533e-15
pre-training;5.097173576022687e-16
the;3.7995749829467577e-16
BERT;3.5985345640036605e-16
model;4.3741627984415125e-16
on;3.6013771206916375e-16
a;4.3812053057970105e-16
similar;3.481243501930755e-16
task;3.8499476299647666e-16
before;3.4565611032440435e-16
fine-tuning;3.8505724627505885e-15
it;4.255043639328408e-16
on;3.682199894515477e-16
the;3.808138307870778e-16
Amazon;3.6605843315379136e-16
reviews;4.179056447477604e-16
data;4.463421667414852e-16
can;3.6870607122769205e-16
lead;3.5412614323022187e-16
to;4.2419885635192796e-16
improved;3.5398427342518165e-16
performance.;0.32592022928563785
Since;3.4553591699078657e-16
inference;3.894468534885445e-16
speed;4.197487873233229e-16
is;3.5704584404363623e-16
a;3.5383658939379394e-16
priority,;7.12597733162398e-16
using;3.7639856166924425e-16
a;3.808556092502919e-16
lighter;4.1456241761595845e-16
version;4.1266769784444416e-16
of;3.8775287141872523e-16
BERT;3.770555377811673e-16
such;3.6742265736695937e-16
as;3.935644266479607e-16
DistilBERT;1.2531187225982571e-15
or;3.89537411506573e-16
utilizing;3.7133792819742883e-16
quantization;4.915755957717966e-16
techniques;3.7366788217629724e-16
can;3.5872883317415153e-16
help;3.625140388031313e-16
make;3.639611635074854e-16
the;4.1515249439138656e-16
model;4.3842515200178596e-16
more;3.5027501745068673e-16
computationally;4.736803885824538e-16
efficient.;3.829799628062022e-16
To;3.775063288927565e-16
evaluate;3.637022726196326e-16
the;5.018357630130027e-16
model's;4.743385813177373e-16
performance,;3.8299495439002355e-15
metrics;3.656554794485114e-16
such;3.767477744988626e-16
as;3.6134361628335443e-16
accuracy,;4.1092454795393093e-16
precision,;3.0469784883335463e-15
and;4.0914828884618775e-16
AUC;4.530213820496024e-16
can;3.6830235162483033e-16
be;4.20055594530101e-16
used.;0.3129087453963489
