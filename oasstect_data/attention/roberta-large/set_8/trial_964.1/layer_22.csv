text;attention
A;1.7416027992882422e-11
good;1.6750364907871413e-11
machine;1.6494403701975642e-11
learning;2.0938936075190534e-11
model;1.7124767321668313e-11
for;1.658707296815072e-11
binary;1.7114433908170893e-11
classification;1.9306535232298426e-11
on;1.6906060877905913e-11
the;1.7856370142907127e-11
Amazon;2.687353392127718e-11
reviews;2.3714196202223226e-11
dataset;2.1423920677460812e-11
is;1.7178221757766433e-11
a;1.8167800394674696e-11
Long;1.7363574518618725e-11
Short-Term;2.890287868334585e-11
Memory;2.078010960410269e-11
(LSTM);2.7823602837741947e-11
network;1.966685518777736e-11
with;1.783938631469504e-11
a;1.6926196854348485e-11
Convolutional;3.0733658453970425e-11
Neural;2.316155427045853e-11
Network;1.9702127709038936e-11
(CNN);1.9658601814939154e-11
layer.;0.17384502926061624
This;1.6859620485422668e-11
model;1.8939047628528662e-11
can;1.652953903237824e-11
be;1.7283139851927456e-11
fine-tuned;2.8127356341384686e-11
or;1.740796219278526e-11
trained;1.687823669571381e-11
from;1.8762327546873677e-11
scratch;1.6651126722823528e-11
depending;1.7367304360374335e-11
on;1.6464161345488502e-11
your;1.6896353286079164e-11
preference.;2.0969628633543617e-11
LSTMs.;0.27702508987540014
are;1.6937536552403955e-11
great;1.7268497505548234e-11
for;1.747880146337964e-11
handling;1.6921940672825017e-11
sequential;1.7001860839221006e-11
data,;2.542007512093496e-10
such;1.785782087353874e-11
as;1.7311549365632606e-11
text;1.7321662888657746e-11
data,;2.4511754445511576e-10
and;2.201642979140494e-11
the;1.6515204875906645e-11
CNN;1.6391585434929012e-11
layer;1.6331184858977967e-11
can;1.6309225534106982e-11
help;1.637380206456744e-11
extract;1.705759723712914e-11
relevant;1.628301616950356e-11
features;1.7843423628972123e-11
from;1.686922892196397e-11
the;1.6561213686164314e-11
text;1.6507701522492347e-11
data.;0.19478935995411684
For;1.825738483560688e-11
inference;1.816702587748164e-11
speed,;2.159508813463831e-11
you;1.739124833412934e-11
can;1.7777165421965465e-11
use;1.646954058327528e-11
the;1.74725248572874e-11
TensorRT;3.0152648846680805e-11
library;1.779648927582779e-11
by;1.6196279555615014e-11
NVIDIA;1.692991069660242e-11
to;1.7121175289635748e-11
optimize;1.748716144491909e-11
the;1.761557808337191e-11
model;1.8400078067118277e-11
for;1.7501305136424848e-11
deployment;1.7365522920721344e-11
on;1.686264604351028e-11
GPUs.;0.181095852175371
In;1.613966509427554e-11
terms;1.6926009077609216e-11
of;1.8065875459913308e-11
metrics,;3.001663961789932e-11
you;1.813481482723619e-11
can;1.815695880536105e-11
use;1.6506072328389734e-11
accuracy,;1.8011420763291324e-11
precision,;2.335877101275291e-10
and;1.9385120700929914e-11
AUC;2.1062014171517366e-11
to;1.653352418181064e-11
evaluate;1.7146110250922192e-11
the;1.9590818941618017e-11
performance;1.8096396474186512e-11
of;1.6856648846631174e-11
the;1.88177300507046e-11
model.;2.1981524229903803e-11
During;1.5983637101267682e-11
training,;3.112273695855402e-11
you;1.8720467437529148e-11
can;1.842397651701807e-11
use;1.7222370933347142e-11
binary;1.7816957136279655e-11
cross-entropy;3.8431961466996607e-11
loss;1.8437129414453098e-11
as;1.6546226779047625e-11
the;1.6719092937045227e-11
loss;1.7143612183711783e-11
function;1.8190651721608784e-11
to;1.6602053826208664e-11
optimize.;0.17324466597953642
